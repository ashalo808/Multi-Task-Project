{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下载bert-base-chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本地模型已存在于 ./bert-base-chinese-local，直接加载\n",
      "模型已从本地成功加载\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# 设置模型保存目录\n",
    "save_directory = \"./bert-base-chinese-local\"\n",
    "\n",
    "# 检查模型是否已存在\n",
    "if os.path.exists(os.path.join(save_directory, \"tokenizer_config.json\")) and \\\n",
    "   os.path.exists(os.path.join(save_directory, \"config.json\")):\n",
    "    print(f\"本地模型已存在于 {save_directory}，直接加载\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(save_directory, local_files_only=True)\n",
    "    model = AutoModel.from_pretrained(save_directory, local_files_only=True)\n",
    "    print(\"模型已从本地成功加载\")\n",
    "else:\n",
    "    print(f\"警告：本地模型目录 {save_directory} 不完整，请确保已正确下载\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added /root/Code/Multi-task Project to system path\n",
      "Current working directory: /root/Code/Multi-task Project\n",
      "Python path: ['/root/miniconda3/envs/multi/lib/python310.zip', '/root/miniconda3/envs/multi/lib/python3.10', '/root/miniconda3/envs/multi/lib/python3.10/lib-dynload', '', '/root/miniconda3/envs/multi/lib/python3.10/site-packages', '/root/Code/Multi-task Project']\n",
      "src directory found: /root/Code/Multi-task Project/src\n",
      "Models directory found: /root/Code/Multi-task Project/src/models\n",
      "Files in models directory:\n",
      "  - core_seq2seq.py\n",
      "  - __init__.py\n",
      "  - __pycache__\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# 修改: 添加项目根目录到Python路径 (适应本地环境)\n",
    "project_root = os.path.dirname(os.path.abspath('__file__'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Added {project_root} to system path\")\n",
    "\n",
    "# 打印当前工作目录和Python路径，用于调试\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Python path: {sys.path}\")\n",
    "\n",
    "# 检查src目录是否存在\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "if os.path.exists(src_path):\n",
    "    print(f\"src directory found: {src_path}\")\n",
    "else:\n",
    "    print(f\"Warning: src directory not found at {src_path}\")\n",
    "\n",
    "# 显示src/models目录的内容\n",
    "models_path = os.path.join(src_path, 'models')\n",
    "if os.path.exists(models_path):\n",
    "    print(f\"Models directory found: {models_path}\")\n",
    "    print(\"Files in models directory:\")\n",
    "    for f in os.listdir(models_path):\n",
    "        print(f\"  - {f}\")\n",
    "else:\n",
    "    print(f\"Warning: models directory not found at {models_path}\")\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:11:41.820539Z",
     "iopub.status.busy": "2025-05-18T04:11:41.820297Z",
     "iopub.status.idle": "2025-05-18T08:00:04.175050Z",
     "shell.execute_reply": "2025-05-18T08:00:04.174276Z",
     "shell.execute_reply.started": "2025-05-18T04:11:41.820523Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using project root: /root/Code/Multi-task Project\n",
      "使用模型路径: /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n",
      "使用GPU: NVIDIA GeForce RTX 4090\n",
      "GPU内存总量: 23.65 GB\n",
      "可用GPU数量: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Starting Multitask Transformer Training with Shared Encoder</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <ul>\n",
       "        <li>Device: cuda</li>\n",
       "        <li>Data File: /root/Code/Multi-task Project/data/raw/pCLUE_train_3.json</li>\n",
       "        <li>Output Directory: /root/Code/Multi-task Project/outputs/transformer_model</li>\n",
       "        <li>Sample Percentage: 80%</li>\n",
       "        <li>Max Samples: 45000</li>\n",
       "        <li>Batch Size: 32</li>\n",
       "        <li>Epochs: 8</li>\n",
       "        <li>Learning Rate: 5e-06</li>\n",
       "    </ul>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and sampling data...\n",
      "Reading file and sampling 80% of data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71884it [00:00, 73909.58it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines read: 71885\n",
      "Sampled data size: 45000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <h4>Dataset Info</h4>\n",
       "    <ul>\n",
       "        <li>Total Samples: 45000</li>\n",
       "        <li>Training Samples: 36000</li>\n",
       "        <li>Validation Samples: 9000</li>\n",
       "    </ul>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从本地加载分词器: ./bert-base-chinese-local\n",
      "Found 139 unique labels\n",
      "Found 139 unique labels\n",
      "Vocabulary size: 21128\n",
      "Using 139 labels for classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:290: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()  # 使用混合精度训练\n",
      "Epoch 1/8:   0%|          | 0/1125 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 1/8: 100%|██████████| 1125/1125 [00:07<00:00, 147.21it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.209804</td>\n",
       "      <td>0.147402</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.209804  0.147402     5100\n",
       "nli       0.003590  0.004098     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 200</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.1204</li>\n",
       "                    <li>Classify Accuracy: 0.2098</li>\n",
       "                    <li>NLI Accuracy: 0.0036</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.0999 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.297647</td>\n",
       "      <td>0.206150</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.304359</td>\n",
       "      <td>0.206931</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.297647  0.206150     5100\n",
       "nli       0.304359  0.206931     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 400</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.3006</li>\n",
       "                    <li>Classify Accuracy: 0.2976</li>\n",
       "                    <li>NLI Accuracy: 0.3044</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.2571 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.343333</td>\n",
       "      <td>0.271776</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.313077</td>\n",
       "      <td>0.276802</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.343333  0.271776     5100\n",
       "nli       0.313077  0.276802     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 600</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.3302</li>\n",
       "                    <li>Classify Accuracy: 0.3433</li>\n",
       "                    <li>NLI Accuracy: 0.3131</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.3016 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.309727</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.33641</td>\n",
       "      <td>0.201629</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify   0.40000  0.309727     5100\n",
       "nli        0.33641  0.201629     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 800</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.3724</li>\n",
       "                    <li>Classify Accuracy: 0.4000</li>\n",
       "                    <li>NLI Accuracy: 0.3364</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.3193 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.409412</td>\n",
       "      <td>0.307336</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.340769</td>\n",
       "      <td>0.250256</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.409412  0.307336     5100\n",
       "nli       0.340769  0.250256     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 1000</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.3797</li>\n",
       "                    <li>Classify Accuracy: 0.4094</li>\n",
       "                    <li>NLI Accuracy: 0.3408</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.3290 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.418235</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.339744</td>\n",
       "      <td>0.253041</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.418235  0.328200     5100\n",
       "nli       0.339744  0.253041     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <h3>End of Epoch 1 Validation Results</h3>\n",
       "        <ul>\n",
       "            <li>Overall Accuracy: 0.3842</li>\n",
       "            <li>Classify Accuracy: 0.4182</li>\n",
       "            <li>NLI Accuracy: 0.3397</li>\n",
       "        </ul>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.3355 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/8:   0%|          | 0/1125 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 2/8: 100%|██████████| 1125/1125 [00:07<00:00, 149.01it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.425294</td>\n",
       "      <td>0.344120</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.342051</td>\n",
       "      <td>0.266825</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.425294  0.344120     5100\n",
       "nli       0.342051  0.266825     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 1200</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.3892</li>\n",
       "                    <li>Classify Accuracy: 0.4253</li>\n",
       "                    <li>NLI Accuracy: 0.3421</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.3468 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.445059</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.343333</td>\n",
       "      <td>0.271763</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.517647  0.445059     5100\n",
       "nli       0.343333  0.271763     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 1400</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.4421</li>\n",
       "                    <li>Classify Accuracy: 0.5176</li>\n",
       "                    <li>NLI Accuracy: 0.3433</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.3981 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.479279</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.353333</td>\n",
       "      <td>0.257214</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.543333  0.479279     5100\n",
       "nli       0.353333  0.257214     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 1600</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.4610</li>\n",
       "                    <li>Classify Accuracy: 0.5433</li>\n",
       "                    <li>NLI Accuracy: 0.3533</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.4184 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.561765</td>\n",
       "      <td>0.490952</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.345641</td>\n",
       "      <td>0.211202</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.561765  0.490952     5100\n",
       "nli       0.345641  0.211202     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 1800</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.4681</li>\n",
       "                    <li>Classify Accuracy: 0.5618</li>\n",
       "                    <li>NLI Accuracy: 0.3456</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.572941</td>\n",
       "      <td>0.508185</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.355128</td>\n",
       "      <td>0.227196</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.572941  0.508185     5100\n",
       "nli       0.355128  0.227196     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 2000</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.4786</li>\n",
       "                    <li>Classify Accuracy: 0.5729</li>\n",
       "                    <li>NLI Accuracy: 0.3551</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.4267 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.583922</td>\n",
       "      <td>0.520860</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.392051</td>\n",
       "      <td>0.316439</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.583922  0.520860     5100\n",
       "nli       0.392051  0.316439     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 2200</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.5008</li>\n",
       "                    <li>Classify Accuracy: 0.5839</li>\n",
       "                    <li>NLI Accuracy: 0.3921</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.4586 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.574706</td>\n",
       "      <td>0.512669</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.433077</td>\n",
       "      <td>0.351150</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.574706  0.512669     5100\n",
       "nli       0.433077  0.351150     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <h3>End of Epoch 2 Validation Results</h3>\n",
       "        <ul>\n",
       "            <li>Overall Accuracy: 0.5133</li>\n",
       "            <li>Classify Accuracy: 0.5747</li>\n",
       "            <li>NLI Accuracy: 0.4331</li>\n",
       "        </ul>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.4743 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/8:   0%|          | 0/1125 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 3/8: 100%|██████████| 1125/1125 [00:07<00:00, 149.61it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.589804</td>\n",
       "      <td>0.528421</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.449487</td>\n",
       "      <td>0.415329</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.589804  0.528421     5100\n",
       "nli       0.449487  0.415329     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 2400</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.5290</li>\n",
       "                    <li>Classify Accuracy: 0.5898</li>\n",
       "                    <li>NLI Accuracy: 0.4495</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.5016 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.589608</td>\n",
       "      <td>0.531436</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.514103</td>\n",
       "      <td>0.490310</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.589608  0.531436     5100\n",
       "nli       0.514103  0.490310     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 2600</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.5569</li>\n",
       "                    <li>Classify Accuracy: 0.5896</li>\n",
       "                    <li>NLI Accuracy: 0.5141</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.5351 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:  99%|█████████▉| 280/282 [00:10<00:00, 28.51it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.551347</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.545128</td>\n",
       "      <td>0.538722</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.593333  0.551347     5100\n",
       "nli       0.545128  0.538722     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 2800</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.5724</li>\n",
       "                    <li>Classify Accuracy: 0.5933</li>\n",
       "                    <li>NLI Accuracy: 0.5451</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.5585 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.601765</td>\n",
       "      <td>0.542774</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.556154</td>\n",
       "      <td>0.537504</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.601765  0.542774     5100\n",
       "nli       0.556154  0.537504     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 3000</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.5820</li>\n",
       "                    <li>Classify Accuracy: 0.6018</li>\n",
       "                    <li>NLI Accuracy: 0.5562</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.5610 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.598235</td>\n",
       "      <td>0.544035</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.602308</td>\n",
       "      <td>0.594506</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.598235  0.544035     5100\n",
       "nli       0.602308  0.594506     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 3200</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6000</li>\n",
       "                    <li>Classify Accuracy: 0.5982</li>\n",
       "                    <li>NLI Accuracy: 0.6023</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.5865 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.601569</td>\n",
       "      <td>0.548366</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.611538</td>\n",
       "      <td>0.598852</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.601569  0.548366     5100\n",
       "nli       0.611538  0.598852     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <h3>End of Epoch 3 Validation Results</h3>\n",
       "        <ul>\n",
       "            <li>Overall Accuracy: 0.6059</li>\n",
       "            <li>Classify Accuracy: 0.6016</li>\n",
       "            <li>NLI Accuracy: 0.6115</li>\n",
       "        </ul>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.5913 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/8:   0%|          | 0/1125 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 4/8: 100%|██████████| 1125/1125 [00:07<00:00, 148.96it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.599412</td>\n",
       "      <td>0.543776</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.628462</td>\n",
       "      <td>0.621704</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.599412  0.543776     5100\n",
       "nli       0.628462  0.621704     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 3400</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6120</li>\n",
       "                    <li>Classify Accuracy: 0.5994</li>\n",
       "                    <li>NLI Accuracy: 0.6285</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.5997 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:  99%|█████████▉| 280/282 [00:10<00:00, 28.46it/s]TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.596471</td>\n",
       "      <td>0.536820</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.624103</td>\n",
       "      <td>0.616921</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.596471  0.536820     5100\n",
       "nli       0.624103  0.616921     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 3600</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6084</li>\n",
       "                    <li>Classify Accuracy: 0.5965</li>\n",
       "                    <li>NLI Accuracy: 0.6241</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.600980</td>\n",
       "      <td>0.542192</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.608205</td>\n",
       "      <td>0.597903</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.600980  0.542192     5100\n",
       "nli       0.608205  0.597903     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 3800</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6041</li>\n",
       "                    <li>Classify Accuracy: 0.6010</li>\n",
       "                    <li>NLI Accuracy: 0.6082</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.598235</td>\n",
       "      <td>0.544215</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.652051</td>\n",
       "      <td>0.647189</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.598235  0.544215     5100\n",
       "nli       0.652051  0.647189     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 4000</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6216</li>\n",
       "                    <li>Classify Accuracy: 0.5982</li>\n",
       "                    <li>NLI Accuracy: 0.6521</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.6115 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.602353</td>\n",
       "      <td>0.547462</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.666923</td>\n",
       "      <td>0.667592</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.602353  0.547462     5100\n",
       "nli       0.666923  0.667592     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 4200</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6303</li>\n",
       "                    <li>Classify Accuracy: 0.6024</li>\n",
       "                    <li>NLI Accuracy: 0.6669</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.6210 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.604902</td>\n",
       "      <td>0.556669</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.666923</td>\n",
       "      <td>0.667655</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.604902  0.556669     5100\n",
       "nli       0.666923  0.667655     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 4400</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6318</li>\n",
       "                    <li>Classify Accuracy: 0.6049</li>\n",
       "                    <li>NLI Accuracy: 0.6669</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.6241 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.609020</td>\n",
       "      <td>0.551506</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.676158</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.609020  0.551506     5100\n",
       "nli       0.676667  0.676158     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <h3>End of Epoch 4 Validation Results</h3>\n",
       "        <ul>\n",
       "            <li>Overall Accuracy: 0.6383</li>\n",
       "            <li>Classify Accuracy: 0.6090</li>\n",
       "            <li>NLI Accuracy: 0.6767</li>\n",
       "        </ul>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.6285 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/8:   0%|          | 0/1125 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 5/8: 100%|██████████| 1125/1125 [00:07<00:00, 153.76it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.610588</td>\n",
       "      <td>0.572502</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.654103</td>\n",
       "      <td>0.645732</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.610588  0.572502     5100\n",
       "nli       0.654103  0.645732     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 4600</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6294</li>\n",
       "                    <li>Classify Accuracy: 0.6106</li>\n",
       "                    <li>NLI Accuracy: 0.6541</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.606078</td>\n",
       "      <td>0.555209</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.676154</td>\n",
       "      <td>0.676298</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.606078  0.555209     5100\n",
       "nli       0.676154  0.676298     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 4800</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6364</li>\n",
       "                    <li>Classify Accuracy: 0.6061</li>\n",
       "                    <li>NLI Accuracy: 0.6762</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.603529</td>\n",
       "      <td>0.553261</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.674103</td>\n",
       "      <td>0.672359</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.603529  0.553261     5100\n",
       "nli       0.674103  0.672359     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 5000</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6341</li>\n",
       "                    <li>Classify Accuracy: 0.6035</li>\n",
       "                    <li>NLI Accuracy: 0.6741</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.607059</td>\n",
       "      <td>0.553378</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.677436</td>\n",
       "      <td>0.677040</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.607059  0.553378     5100\n",
       "nli       0.677436  0.677040     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 5200</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6376</li>\n",
       "                    <li>Classify Accuracy: 0.6071</li>\n",
       "                    <li>NLI Accuracy: 0.6774</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.6290 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.609216</td>\n",
       "      <td>0.555003</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.682821</td>\n",
       "      <td>0.682345</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.609216  0.555003     5100\n",
       "nli       0.682821  0.682345     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 5400</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6411</li>\n",
       "                    <li>Classify Accuracy: 0.6092</li>\n",
       "                    <li>NLI Accuracy: 0.6828</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.6326 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.609608</td>\n",
       "      <td>0.558493</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.680256</td>\n",
       "      <td>0.679858</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.609608  0.558493     5100\n",
       "nli       0.680256  0.679858     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 5600</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6402</li>\n",
       "                    <li>Classify Accuracy: 0.6096</li>\n",
       "                    <li>NLI Accuracy: 0.6803</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.611176</td>\n",
       "      <td>0.576956</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.684895</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.611176  0.576956     5100\n",
       "nli       0.684615  0.684895     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <h3>End of Epoch 5 Validation Results</h3>\n",
       "        <ul>\n",
       "            <li>Overall Accuracy: 0.6430</li>\n",
       "            <li>Classify Accuracy: 0.6112</li>\n",
       "            <li>NLI Accuracy: 0.6846</li>\n",
       "        </ul>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.6385 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/8:   0%|          | 0/1125 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 6/8: 100%|██████████| 1125/1125 [00:07<00:00, 151.94it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.612745</td>\n",
       "      <td>0.56378</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.683077</td>\n",
       "      <td>0.68375</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy       f1  support\n",
       "classify  0.612745  0.56378     5100\n",
       "nli       0.683077  0.68375     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 5800</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6432</li>\n",
       "                    <li>Classify Accuracy: 0.6127</li>\n",
       "                    <li>NLI Accuracy: 0.6831</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.561671</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.686154</td>\n",
       "      <td>0.686787</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.611765  0.561671     5100\n",
       "nli       0.686154  0.686787     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 6000</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6440</li>\n",
       "                    <li>Classify Accuracy: 0.6118</li>\n",
       "                    <li>NLI Accuracy: 0.6862</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.611961</td>\n",
       "      <td>0.566418</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.688462</td>\n",
       "      <td>0.688428</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.611961  0.566418     5100\n",
       "nli       0.688462  0.688428     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 6200</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6451</li>\n",
       "                    <li>Classify Accuracy: 0.6120</li>\n",
       "                    <li>NLI Accuracy: 0.6885</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.614706</td>\n",
       "      <td>0.562048</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.689744</td>\n",
       "      <td>0.689966</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.614706  0.562048     5100\n",
       "nli       0.689744  0.689966     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 6400</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6472</li>\n",
       "                    <li>Classify Accuracy: 0.6147</li>\n",
       "                    <li>NLI Accuracy: 0.6897</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.6391 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:  99%|█████████▉| 280/282 [00:10<00:00, 28.18it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.612549</td>\n",
       "      <td>0.560946</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.691282</td>\n",
       "      <td>0.691357</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.612549  0.560946     5100\n",
       "nli       0.691282  0.691357     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 6600</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6467</li>\n",
       "                    <li>Classify Accuracy: 0.6125</li>\n",
       "                    <li>NLI Accuracy: 0.6913</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.610196</td>\n",
       "      <td>0.573484</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.689231</td>\n",
       "      <td>0.687849</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.610196  0.573484     5100\n",
       "nli       0.689231  0.687849     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <h3>End of Epoch 6 Validation Results</h3>\n",
       "        <ul>\n",
       "            <li>Overall Accuracy: 0.6444</li>\n",
       "            <li>Classify Accuracy: 0.6102</li>\n",
       "            <li>NLI Accuracy: 0.6892</li>\n",
       "        </ul>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.6393 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/8:   0%|          | 0/1125 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 7/8: 100%|██████████| 1125/1125 [00:07<00:00, 150.29it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.614510</td>\n",
       "      <td>0.570529</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.693846</td>\n",
       "      <td>0.694471</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.614510  0.570529     5100\n",
       "nli       0.693846  0.694471     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 6800</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6489</li>\n",
       "                    <li>Classify Accuracy: 0.6145</li>\n",
       "                    <li>NLI Accuracy: 0.6938</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.6428 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.610784</td>\n",
       "      <td>0.563250</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.694872</td>\n",
       "      <td>0.695146</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.610784  0.563250     5100\n",
       "nli       0.694872  0.695146     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 7000</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6472</li>\n",
       "                    <li>Classify Accuracy: 0.6108</li>\n",
       "                    <li>NLI Accuracy: 0.6949</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.615686</td>\n",
       "      <td>0.564347</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.693590</td>\n",
       "      <td>0.693504</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.615686  0.564347     5100\n",
       "nli       0.693590  0.693504     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 7200</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6494</li>\n",
       "                    <li>Classify Accuracy: 0.6157</li>\n",
       "                    <li>NLI Accuracy: 0.6936</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.617843</td>\n",
       "      <td>0.569016</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.694615</td>\n",
       "      <td>0.694870</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.617843  0.569016     5100\n",
       "nli       0.694615  0.694870     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 7400</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6511</li>\n",
       "                    <li>Classify Accuracy: 0.6178</li>\n",
       "                    <li>NLI Accuracy: 0.6946</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.6441 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.612353</td>\n",
       "      <td>0.565480</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.682077</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.612353  0.565480     5100\n",
       "nli       0.684615  0.682077     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 7600</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6437</li>\n",
       "                    <li>Classify Accuracy: 0.6124</li>\n",
       "                    <li>NLI Accuracy: 0.6846</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.612745</td>\n",
       "      <td>0.567091</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.695808</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.612745  0.567091     5100\n",
       "nli       0.696154  0.695808     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 7800</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6489</li>\n",
       "                    <li>Classify Accuracy: 0.6127</li>\n",
       "                    <li>NLI Accuracy: 0.6962</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.615882</td>\n",
       "      <td>0.575354</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.694615</td>\n",
       "      <td>0.695442</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.615882  0.575354     5100\n",
       "nli       0.694615  0.695442     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <h3>End of Epoch 7 Validation Results</h3>\n",
       "        <ul>\n",
       "            <li>Overall Accuracy: 0.6500</li>\n",
       "            <li>Classify Accuracy: 0.6159</li>\n",
       "            <li>NLI Accuracy: 0.6946</li>\n",
       "        </ul>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.6448 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/8:   0%|          | 0/1125 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 8/8: 100%|██████████| 1125/1125 [00:07<00:00, 152.90it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.616471</td>\n",
       "      <td>0.568442</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.697692</td>\n",
       "      <td>0.698321</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.616471  0.568442     5100\n",
       "nli       0.697692  0.698321     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 8000</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6517</li>\n",
       "                    <li>Classify Accuracy: 0.6165</li>\n",
       "                    <li>NLI Accuracy: 0.6977</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.6449 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.613922</td>\n",
       "      <td>0.563962</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.696410</td>\n",
       "      <td>0.696723</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.613922  0.563962     5100\n",
       "nli       0.696410  0.696723     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 8200</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6497</li>\n",
       "                    <li>Classify Accuracy: 0.6139</li>\n",
       "                    <li>NLI Accuracy: 0.6964</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.618824</td>\n",
       "      <td>0.570840</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.697179</td>\n",
       "      <td>0.697395</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.618824  0.570840     5100\n",
       "nli       0.697179  0.697395     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 8400</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6528</li>\n",
       "                    <li>Classify Accuracy: 0.6188</li>\n",
       "                    <li>NLI Accuracy: 0.6972</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score: 0.6459 at /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.615098</td>\n",
       "      <td>0.564044</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.696923</td>\n",
       "      <td>0.696830</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.615098  0.564044     5100\n",
       "nli       0.696923  0.696830     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 8600</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6506</li>\n",
       "                    <li>Classify Accuracy: 0.6151</li>\n",
       "                    <li>NLI Accuracy: 0.6969</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.615490</td>\n",
       "      <td>0.565885</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.699487</td>\n",
       "      <td>0.699847</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.615490  0.565885     5100\n",
       "nli       0.699487  0.699847     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 8800</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6519</li>\n",
       "                    <li>Classify Accuracy: 0.6155</li>\n",
       "                    <li>NLI Accuracy: 0.6995</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488/2976806296.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating:  99%|█████████▉| 280/282 [00:10<00:00, 28.35it/s]TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.615490</td>\n",
       "      <td>0.566198</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.700513</td>\n",
       "      <td>0.701016</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.615490  0.566198     5100\n",
       "nli       0.700513  0.701016     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <h4>Validation Results at Step 9000</h4>\n",
       "                <ul>\n",
       "                    <li>Overall Accuracy: 0.6523</li>\n",
       "                    <li>Classify Accuracy: 0.6155</li>\n",
       "                    <li>NLI Accuracy: 0.7005</li>\n",
       "                </ul>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 27.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.615686</td>\n",
       "      <td>0.566411</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.700513</td>\n",
       "      <td>0.701016</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.615686  0.566411     5100\n",
       "nli       0.700513  0.701016     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <h3>End of Epoch 8 Validation Results</h3>\n",
       "        <ul>\n",
       "            <li>Overall Accuracy: 0.6524</li>\n",
       "            <li>Classify Accuracy: 0.6157</li>\n",
       "            <li>NLI Accuracy: 0.7005</li>\n",
       "        </ul>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载最佳模型用于最终评估: /root/Code/Multi-task Project/test_outputs/multitask_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/282 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1488/2976806296.py:468: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Evaluating: 100%|██████████| 282/282 [00:10<00:00, 26.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Detailed Task Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classify</th>\n",
       "      <td>0.619412</td>\n",
       "      <td>0.571874</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>0.697179</td>\n",
       "      <td>0.697395</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1  support\n",
       "classify  0.619412  0.571874     5100\n",
       "nli       0.697179  0.697395     3900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Final Evaluation Results</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <ul>\n",
       "        <li>Overall Accuracy: 0.6531</li>\n",
       "        <li>Classify Accuracy: 0.6194</li>\n",
       "        <li>NLI Accuracy: 0.6972</li>\n",
       "        <li>Overall F1 Score: 0.6391</li>\n",
       "    </ul>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label map saved for inference\n",
      "Model configuration saved\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, HTML\n",
    "import sys\n",
    "\n",
    "# 添加项目根目录到Python路径\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# 导入我们自己的Seq2SeqTransformer模型\n",
    "from src.models.core_seq2seq import Seq2SeqTransformer, PositionalEncoding\n",
    "\n",
    "# 设置随机种子以保证可重复性\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# 检测设备\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"使用GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU内存总量: {torch.cuda.get_device_properties(0).total_memory / 1024 / 1024 / 1024:.2f} GB\")\n",
    "        print(f\"可用GPU数量: {torch.cuda.device_count()}\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"使用CPU\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "# 流式加载JSON数据并随机抽样\n",
    "def load_json_data_with_sampling(file_path, sample_percentage=10, max_samples=None, task_types=None):\n",
    "    sample_prob = sample_percentage / 100\n",
    "    sampled_data = []\n",
    "    line_count = 0\n",
    "    \n",
    "    print(f\"Reading file and sampling {sample_percentage}% of data...\")\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f):\n",
    "            line_count += 1\n",
    "            \n",
    "            if random.random() <= sample_prob:\n",
    "                try:\n",
    "                    item = json.loads(line.strip())\n",
    "                    \n",
    "                    if task_types is not None and item.get('type') not in task_types:\n",
    "                        continue\n",
    "                        \n",
    "                    sampled_data.append(item)\n",
    "                    \n",
    "                    if max_samples and len(sampled_data) >= max_samples:\n",
    "                        break\n",
    "                        \n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "    \n",
    "    print(f\"Total lines read: {line_count}\")\n",
    "    print(f\"Sampled data size: {len(sampled_data)}\")\n",
    "    \n",
    "    return sampled_data\n",
    "\n",
    "# 自定义数据集类 - 修改以适应Seq2SeqTransformer模型\n",
    "class MultiTaskDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512, pad_idx=0):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "        # 收集所有可能的标签\n",
    "        self.all_labels = set()\n",
    "        for item in data:\n",
    "            if 'answer_choices' in item and item['answer_choices']:\n",
    "                for choice in item['answer_choices']:\n",
    "                    self.all_labels.add(choice)\n",
    "        self.label_map = {label: i for i, label in enumerate(sorted(self.all_labels))}\n",
    "        print(f\"Found {len(self.label_map)} unique labels\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            item = self.data[idx]\n",
    "            input_text = item['input']\n",
    "            target_text = item['target']\n",
    "            task_type = item['type']\n",
    "            \n",
    "            # 针对不同任务类型的处理\n",
    "            if task_type == 'nli':\n",
    "                parts = input_text.split('，')\n",
    "                if len(parts) > 1:\n",
    "                    premise = parts[0].strip()\n",
    "                    hypothesis_parts = parts[1:]\n",
    "                    hypothesis = '，'.join(hypothesis_parts).split('？')[0].strip() if '？' in parts[-1] else '，'.join(hypothesis_parts).strip()\n",
    "                    input_text = f\"{premise} [SEP] {hypothesis}\"\n",
    "            \n",
    "            # 数据增强 - 对于分类任务可以添加一些随机噪声或替换\n",
    "            if task_type == 'classify' and random.random() < 0.2:\n",
    "                words = list(input_text)\n",
    "                # 随机替换、删除或插入字符\n",
    "                for i in range(min(5, len(words))):\n",
    "                    pos = random.randint(0, len(words) - 1)\n",
    "                    if random.random() < 0.5:  # 替换\n",
    "                        words[pos] = random.choice(\"的地得了吗呢啊哦嗯呀哈\")\n",
    "                    else:  # 删除\n",
    "                        if len(words) > 10:  # 确保不会删除太多\n",
    "                            words.pop(pos)\n",
    "                            break\n",
    "                input_text = ''.join(words)\n",
    "            \n",
    "            # 使用更有效的tokenizer处理方式\n",
    "            encoding = self.tokenizer(\n",
    "                input_text, \n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                return_tensors='pt',\n",
    "                return_token_type_ids=True  # 特别对NLI任务有用\n",
    "            )\n",
    "            \n",
    "            # 处理目标文本为ID\n",
    "            answer_choices = item.get('answer_choices', [])\n",
    "            \n",
    "            # 处理标签\n",
    "            if task_type in ['classify', 'nli'] and answer_choices:\n",
    "                try:\n",
    "                    if target_text in self.label_map:\n",
    "                        label_idx = self.label_map[target_text]\n",
    "                    elif target_text in answer_choices:\n",
    "                        label_idx = answer_choices.index(target_text)\n",
    "                    else:\n",
    "                        label_idx = 0\n",
    "                    label = torch.tensor(label_idx, dtype=torch.long)\n",
    "                except ValueError:\n",
    "                    label = torch.tensor(0, dtype=torch.long)\n",
    "            else:\n",
    "                label = torch.tensor(-100, dtype=torch.long)\n",
    "            \n",
    "            for key in encoding:\n",
    "                encoding[key] = encoding[key].squeeze(0)\n",
    "            \n",
    "            # 为BERT模型准备必要的数据\n",
    "            return {\n",
    "                'input_ids': encoding['input_ids'],\n",
    "                'attention_mask': encoding['attention_mask'],\n",
    "                'token_type_ids': encoding.get('token_type_ids', None),\n",
    "                'src_padding_mask': (encoding['input_ids'] == self.pad_idx),\n",
    "                'label': label,\n",
    "                'task_type': task_type,\n",
    "                'target_text': target_text,\n",
    "                'answer_choices': answer_choices\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing item at index {idx}: {e}\")\n",
    "            # 返回一个默认项，避免批处理失败\n",
    "            return None\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"处理不同大小的批次数据\"\"\"\n",
    "    # 过滤掉None值\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    \n",
    "    if len(batch) == 0:\n",
    "        return {}\n",
    "    \n",
    "    # 收集所有键\n",
    "    keys = batch[0].keys()\n",
    "    \n",
    "    result = {}\n",
    "    for key in keys:\n",
    "        if key == 'task_type' or key == 'target_text' or key == 'answer_choices':\n",
    "            # 对于字符串或列表类型的字段，直接添加到结果中\n",
    "            result[key] = [item[key] for item in batch]\n",
    "        elif isinstance(batch[0][key], torch.Tensor):\n",
    "            # 检查所有项目的形状是否一致\n",
    "            shapes = [item[key].shape for item in batch]\n",
    "            if all(shape == shapes[0] for shape in shapes):\n",
    "                # 如果所有形状一致，则进行常规的堆叠\n",
    "                result[key] = torch.stack([item[key] for item in batch])\n",
    "            else:\n",
    "                # 如果形状不一致，则进行填充或其他处理\n",
    "                # 这里我们使用最大长度进行填充\n",
    "                max_len = max(shape[0] for shape in shapes)\n",
    "                padded_tensors = []\n",
    "                for item in batch:\n",
    "                    tensor = item[key]\n",
    "                    if tensor.shape[0] < max_len:\n",
    "                        padding = torch.zeros(max_len - tensor.shape[0], *tensor.shape[1:], \n",
    "                                             dtype=tensor.dtype, device=tensor.device)\n",
    "                        tensor = torch.cat([tensor, padding], dim=0)\n",
    "                    padded_tensors.append(tensor)\n",
    "                result[key] = torch.stack(padded_tensors)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# 数据加载器创建函数\n",
    "def create_dataloaders(train_data, val_data, tokenizer, batch_size=8):\n",
    "    train_dataset = MultiTaskDataset(train_data, tokenizer)\n",
    "    val_dataset = MultiTaskDataset(val_data, tokenizer)\n",
    "    \n",
    "    # 使用num_workers加速数据加载\n",
    "    num_workers = min(4, os.cpu_count())\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,  # GPU加速\n",
    "        collate_fn=custom_collate_fn  # 使用自定义的collate函数\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,  # GPU加速\n",
    "        collate_fn=custom_collate_fn  # 使用自定义的collate函数\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, train_dataset.label_map\n",
    "\n",
    "# 使用预训练的BERT替代自定义编码器\n",
    "class MultitaskBertModel(nn.Module):\n",
    "    def __init__(self, num_labels=2):\n",
    "        super(MultitaskBertModel, self).__init__()\n",
    "        \n",
    "        # 加载预训练的BERT模型\n",
    "        self.bert = AutoModel.from_pretrained(\"./bert-base-chinese-local\")\n",
    "        \n",
    "        # 任务特定的头部\n",
    "        self.classify_head = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        self.nli_head = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        \n",
    "        # 初始化权重\n",
    "        nn.init.xavier_uniform_(self.classify_head.weight)\n",
    "        nn.init.xavier_uniform_(self.nli_head.weight)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, task_type=None):\n",
    "        # 使用BERT提取特征\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        # 获取[CLS]的表示用于分类\n",
    "        pooled_output = outputs.pooler_output\n",
    "        \n",
    "        if isinstance(task_type, list):\n",
    "            # 批处理多个样本时使用\n",
    "            results = []\n",
    "            for i, t in enumerate(task_type):\n",
    "                if t == 'classify':\n",
    "                    results.append(self.classify_head(pooled_output[i:i+1]))\n",
    "                elif t == 'nli':\n",
    "                    results.append(self.nli_head(pooled_output[i:i+1]))\n",
    "                else:\n",
    "                    results.append(self.classify_head(pooled_output[i:i+1]))\n",
    "            return torch.cat(results, dim=0)\n",
    "        else:\n",
    "            # 单个样本或同类型批次处理\n",
    "            if task_type == 'classify':\n",
    "                return self.classify_head(pooled_output)\n",
    "            elif task_type == 'nli':\n",
    "                return self.nli_head(pooled_output)\n",
    "            else:\n",
    "                return self.classify_head(pooled_output)\n",
    "\n",
    "# 训练函数 - 优化以适用于GPU\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, device, best_model_path, num_epochs=3, eval_steps=100):\n",
    "    best_val_score = 0\n",
    "    global_step = 0\n",
    "    scaler = torch.cuda.amp.GradScaler()  # 使用混合精度训练\n",
    "    patience = 3  # 早停的耐心参数\n",
    "    early_stopping_counter = 0  # 早停计数器\n",
    "    \n",
    "    # 用于Kaggle输出的结果记录\n",
    "    results_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            # 检查批次是否为空\n",
    "            if not batch or len(batch) == 0:\n",
    "                print(\"跳过空批次\")\n",
    "                continue\n",
    "                \n",
    "            # 检查输入IDs是否存在\n",
    "            if 'input_ids' not in batch:\n",
    "                print(f\"批次 {batch_idx} 中没有 input_ids，跳过\")\n",
    "                continue\n",
    "        \n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch.get('attention_mask', None)\n",
    "            if attention_mask is not None:\n",
    "                attention_mask = attention_mask.to(device)\n",
    "            src_padding_mask = batch.get('src_padding_mask', None)\n",
    "            if src_padding_mask is not None:\n",
    "                src_padding_mask = src_padding_mask.to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            task_types = batch['task_type']\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 仅处理有效样本\n",
    "            valid_indices = (labels != -100).nonzero(as_tuple=True)[0]\n",
    "            \n",
    "            if len(valid_indices) > 0:\n",
    "                batch_input_ids = input_ids[valid_indices]\n",
    "                batch_attention_mask = attention_mask[valid_indices] if attention_mask is not None else None\n",
    "                batch_src_padding_mask = src_padding_mask[valid_indices] if src_padding_mask is not None else None\n",
    "                batch_labels = labels[valid_indices]\n",
    "                batch_task_types = [task_types[i] for i in valid_indices]\n",
    "                \n",
    "                # 使用混合精度训练\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    # 获取token_type_ids并移至设备\n",
    "                    token_type_ids = batch.get('token_type_ids', None)\n",
    "                    if token_type_ids is not None:\n",
    "                        # 先将索引移到与token_type_ids相同的设备上 (CPU)\n",
    "                        cpu_valid_indices = valid_indices.cpu()\n",
    "                        # 使用CPU上的索引切片CPU上的张量\n",
    "                        token_type_ids = token_type_ids[cpu_valid_indices]\n",
    "                        # 然后将结果移到目标设备\n",
    "                        token_type_ids = token_type_ids.to(device)\n",
    "                        \n",
    "                    outputs = model(\n",
    "                        input_ids=batch_input_ids,\n",
    "                        attention_mask=batch_attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        task_type=batch_task_types\n",
    "                    )\n",
    "                    \n",
    "                    # 为不同任务设置权重\n",
    "                    task_weights = {\n",
    "                        'classify': 1.0,\n",
    "                        'nli': 1.5  # 如果NLI任务较难，可以给它更高的权重\n",
    "                    }\n",
    "                    \n",
    "                    # 计算每个样本的任务权重\n",
    "                    sample_weights = torch.tensor([task_weights.get(t, 1.0) for t in batch_task_types], \n",
    "                                            device=device)\n",
    "                    \n",
    "                    loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "                    losses = loss_fn(outputs, batch_labels)\n",
    "                    # 应用任务权重\n",
    "                    loss = (losses * sample_weights).mean()\n",
    "                \n",
    "                # 使用混合精度训练优化反向传播\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                \n",
    "                scheduler.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                global_step += 1\n",
    "            \n",
    "            progress_bar.set_postfix({\"Loss\": f\"{total_loss/(batch_idx+1):.4f}\"})\n",
    "            \n",
    "            if global_step % eval_steps == 0:                \n",
    "                val_results = evaluate(model, val_loader, device)\n",
    "                results_history.append({\n",
    "                    'step': global_step,\n",
    "                    'epoch': epoch+1,\n",
    "                    'val_results': val_results\n",
    "                })\n",
    "                \n",
    "                # 在Kaggle中显示美观的验证结果\n",
    "                display(HTML(f\"\"\"\n",
    "                <h4>Validation Results at Step {global_step}</h4>\n",
    "                <ul>\n",
    "                    <li>Overall Accuracy: {val_results.get('overall_accuracy', 0):.4f}</li>\n",
    "                    <li>Classify Accuracy: {val_results.get('classify_accuracy', 0):.4f}</li>\n",
    "                    <li>NLI Accuracy: {val_results.get('nli_accuracy', 0):.4f}</li>\n",
    "                </ul>\n",
    "                \"\"\"))\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                val_score = sum(val_results.values()) / len(val_results) if val_results else 0\n",
    "                if val_score > best_val_score:\n",
    "                    best_val_score = val_score\n",
    "                    torch.save(model.state_dict(), best_model_path)\n",
    "                    print(f\"New best model saved with score: {best_val_score:.4f} at {best_model_path}\")\n",
    "        \n",
    "        # 每个epoch结束后的评估\n",
    "        val_results = evaluate(model, val_loader, device)\n",
    "        results_history.append({\n",
    "            'epoch': epoch+1,\n",
    "            'val_results': val_results\n",
    "        })\n",
    "        \n",
    "        display(HTML(f\"\"\"\n",
    "        <h3>End of Epoch {epoch+1} Validation Results</h3>\n",
    "        <ul>\n",
    "            <li>Overall Accuracy: {val_results.get('overall_accuracy', 0):.4f}</li>\n",
    "            <li>Classify Accuracy: {val_results.get('classify_accuracy', 0):.4f}</li>\n",
    "            <li>NLI Accuracy: {val_results.get('nli_accuracy', 0):.4f}</li>\n",
    "        </ul>\n",
    "        \"\"\"))\n",
    "        \n",
    "        val_score = sum(val_results.values()) / len(val_results) if val_results else 0\n",
    "        if val_score > best_val_score:\n",
    "            best_val_score = val_score\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"New best model saved with score: {best_val_score:.4f} at {best_model_path}\")\n",
    "            \n",
    "        # GPU内存回收\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return results_history\n",
    "\n",
    "# 评估函数保持不变\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_task_types = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch.get('attention_mask', None)\n",
    "            if attention_mask is not None:\n",
    "                attention_mask = attention_mask.to(device)\n",
    "            src_padding_mask = batch.get('src_padding_mask', None)\n",
    "            if src_padding_mask is not None:\n",
    "                src_padding_mask = src_padding_mask.to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            task_types = batch['task_type']\n",
    "            \n",
    "            valid_indices = (labels != -100).nonzero(as_tuple=True)[0]\n",
    "            \n",
    "            if len(valid_indices) > 0:\n",
    "                batch_input_ids = input_ids[valid_indices]\n",
    "                batch_attention_mask = attention_mask[valid_indices] if attention_mask is not None else None\n",
    "                batch_src_padding_mask = src_padding_mask[valid_indices] if src_padding_mask is not None else None\n",
    "                batch_labels = labels[valid_indices]\n",
    "                batch_task_types = [task_types[i] for i in valid_indices]\n",
    "                \n",
    "                # 使用混合精度进行推理\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    # 获取token_type_ids并移至设备\n",
    "                    token_type_ids = batch.get('token_type_ids', None)\n",
    "                    if token_type_ids is not None:\n",
    "                        # 先将索引移到与token_type_ids相同的设备上 (CPU)\n",
    "                        cpu_valid_indices = valid_indices.cpu()\n",
    "                        # 使用CPU上的索引切片CPU上的张量\n",
    "                        token_type_ids = token_type_ids[cpu_valid_indices]\n",
    "                        # 然后将结果移到目标设备\n",
    "                        token_type_ids = token_type_ids.to(device)\n",
    "                        \n",
    "                    outputs = model(\n",
    "                        input_ids=batch_input_ids,\n",
    "                        attention_mask=batch_attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        task_type=batch_task_types\n",
    "                    )\n",
    "                \n",
    "                preds = torch.argmax(outputs, dim=-1)\n",
    "                \n",
    "                # 转移到CPU以进行后续处理\n",
    "                preds = preds.cpu().numpy()\n",
    "                batch_labels = batch_labels.cpu().numpy()\n",
    "                \n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(batch_labels)\n",
    "                all_task_types.extend(batch_task_types)\n",
    "    \n",
    "    results = {}\n",
    "    if all_preds:\n",
    "        overall_acc = accuracy_score(all_labels, all_preds)\n",
    "        results['overall_accuracy'] = overall_acc\n",
    "        \n",
    "        # 计算F1分数\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        results['overall_f1'] = f1\n",
    "    \n",
    "    # 计算任务特定指标\n",
    "    task_metrics = {}\n",
    "    for task_type in set(all_task_types):\n",
    "        task_indices = [i for i, t in enumerate(all_task_types) if t == task_type]\n",
    "        if task_indices:\n",
    "            task_preds = [all_preds[i] for i in task_indices]\n",
    "            task_labels = [all_labels[i] for i in task_indices]\n",
    "            task_acc = accuracy_score(task_labels, task_preds)\n",
    "            task_f1 = f1_score(task_labels, task_preds, average='weighted')\n",
    "            \n",
    "            results[f'{task_type}_accuracy'] = task_acc\n",
    "            results[f'{task_type}_f1'] = task_f1\n",
    "            \n",
    "            task_metrics[task_type] = {\n",
    "                'accuracy': task_acc,\n",
    "                'f1': task_f1,\n",
    "                'support': len(task_indices)\n",
    "            }\n",
    "    \n",
    "    # 在Kaggle中显示详细结果表格\n",
    "    if task_metrics:\n",
    "        metrics_df = pd.DataFrame.from_dict(task_metrics, orient='index')\n",
    "        display(HTML(\"<h4>Detailed Task Metrics</h4>\"))\n",
    "        display(metrics_df)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # 参数设置\n",
    "    # 检测运行环境并设置相应的路径\n",
    "    is_kaggle = os.path.exists('/kaggle') and '/kaggle/working' in os.getcwd()\n",
    "\n",
    "    # 确保使用正确的项目根目录\n",
    "    project_root = os.path.dirname(os.path.abspath('__file__'))\n",
    "    possible_paths = [\n",
    "        os.path.dirname(os.path.abspath('__file__')),  # 当前文件所在目录\n",
    "        os.getcwd(),  # 当前工作目录\n",
    "        '/root/Code/Multi-task Project'  # 从错误消息推断的完整路径\n",
    "    ]\n",
    "\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            project_root = path\n",
    "            break\n",
    "\n",
    "    print(f\"Using project root: {project_root}\")\n",
    "\n",
    "    # 定义best_model_path变量\n",
    "    if is_kaggle:\n",
    "        model_path = '/kaggle/working/best_multitask_transformer.pt'\n",
    "        best_model_path = model_path  # 添加这行定义best_model_path\n",
    "        output_dir = '/kaggle/working/outputs'\n",
    "        data_file = '/kaggle/input/multitask-data/data.jsonl'  # 根据实际路径调整\n",
    "    else:\n",
    "        # 本地环境 - 尝试多种可能的模型路径\n",
    "        model_paths = [\n",
    "            os.path.join(project_root, \"outputs\", \"transformer_model\", \"best_multitask_transformer.pt\"),\n",
    "            os.path.join(project_root, \"test_outputs\", \"multitask_model.pth\"),\n",
    "            os.path.join(project_root, \"best_multitask_transformer.pt\"),  # 检查根目录\n",
    "            \"./best_multitask_transformer.pt\"  # 检查当前目录\n",
    "        ]\n",
    "        \n",
    "        model_path = None\n",
    "        for path in model_paths:\n",
    "            if os.path.exists(path):\n",
    "                model_path = path\n",
    "                break\n",
    "        \n",
    "        if model_path is None:\n",
    "            # 如果所有路径都不存在，使用默认路径但创建一个新模型\n",
    "            model_path = os.path.join(project_root, \"outputs\", \"transformer_model\", \"best_multitask_transformer.pt\")\n",
    "            print(f\"警告: 没有找到现有模型，将创建一个新模型实例\")\n",
    "        \n",
    "        best_model_path = model_path  # 添加这行定义best_model_path\n",
    "            \n",
    "        # 设置本地环境的输出目录和数据文件路径\n",
    "        output_dir = os.path.join(project_root, \"outputs\", \"transformer_model\")\n",
    "        data_file = os.path.join(project_root, \"data/raw\", \"pCLUE_train_3.json\") \n",
    "\n",
    "    print(f\"使用模型路径: {model_path}\")\n",
    "    \n",
    "    sample_percentage = 80\n",
    "    max_samples = 45000\n",
    "    batch_size = 32  # 增加批次大小\n",
    "    epochs = 8  # 增加训练轮数\n",
    "    lr = 5e-6  # 降低学习率\n",
    "    weight_decay = 0.01  # 添加权重衰减\n",
    "    eval_steps = 200\n",
    "    seed = 42\n",
    "    task_types = [\"classify\", \"nli\"]\n",
    "    \n",
    "    # 确保输出目录存在\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 检查数据文件是否存在\n",
    "    if not os.path.exists(data_file):\n",
    "        raise FileNotFoundError(f\"数据文件 '{data_file}' 不存在，请检查路径\")\n",
    "    \n",
    "    set_seed(seed)\n",
    "    \n",
    "    # 获取设备\n",
    "    device = get_device()\n",
    "    \n",
    "    # 显示开始信息\n",
    "    display(HTML(\"<h2>Starting Multitask Transformer Training with Shared Encoder</h2>\"))\n",
    "    display(HTML(f\"\"\"\n",
    "    <ul>\n",
    "        <li>Device: {device}</li>\n",
    "        <li>Data File: {data_file}</li>\n",
    "        <li>Output Directory: {output_dir}</li>\n",
    "        <li>Sample Percentage: {sample_percentage}%</li>\n",
    "        <li>Max Samples: {max_samples}</li>\n",
    "        <li>Batch Size: {batch_size}</li>\n",
    "        <li>Epochs: {epochs}</li>\n",
    "        <li>Learning Rate: {lr}</li>\n",
    "    </ul>\n",
    "    \"\"\"))\n",
    "    \n",
    "    # 加载数据\n",
    "    print(\"Loading and sampling data...\")\n",
    "    all_data = load_json_data_with_sampling(\n",
    "        data_file,\n",
    "        sample_percentage=sample_percentage,\n",
    "        max_samples=max_samples,\n",
    "        task_types=task_types\n",
    "    )\n",
    "    \n",
    "    # 确保每个样本都有答案选项\n",
    "    for item in all_data:\n",
    "        if 'answer_choices' not in item or not item['answer_choices']:\n",
    "            item['answer_choices'] = [\"是的\", \"不是\"] if item['type'] == 'nli' else [\"选项A\", \"选项B\"]\n",
    "    \n",
    "    # 分割数据集\n",
    "    train_size = int(0.8 * len(all_data))\n",
    "    random.shuffle(all_data)\n",
    "    train_data = all_data[:train_size]\n",
    "    val_data = all_data[train_size:]\n",
    "    \n",
    "    display(HTML(f\"\"\"\n",
    "    <h4>Dataset Info</h4>\n",
    "    <ul>\n",
    "        <li>Total Samples: {len(all_data)}</li>\n",
    "        <li>Training Samples: {len(train_data)}</li>\n",
    "        <li>Validation Samples: {len(val_data)}</li>\n",
    "    </ul>\n",
    "    \"\"\"))\n",
    "    \n",
    "    local_model_path = \"./bert-base-chinese-local\"\n",
    "    if os.path.exists(os.path.join(local_model_path, \"tokenizer_config.json\")):\n",
    "        print(f\"从本地加载分词器: {local_model_path}\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(local_model_path, local_files_only=True)\n",
    "    else:\n",
    "        print(f\"警告：本地分词器未找到，尝试降级方案\")\n",
    "        # 尝试使用相对路径\n",
    "        alternative_paths = [\n",
    "            os.path.join(project_root, \"bert-base-chinese-local\"),\n",
    "            \"/root/Code/Multi-task Project/bert-base-chinese-local\"\n",
    "        ]\n",
    "        found_model = False\n",
    "        for path in alternative_paths:\n",
    "            if os.path.exists(os.path.join(path, \"tokenizer_config.json\")):\n",
    "                print(f\"从路径加载分词器: {path}\")\n",
    "                tokenizer = AutoTokenizer.from_pretrained(path, local_files_only=True)\n",
    "                found_model = True\n",
    "                break\n",
    "        \n",
    "        if not found_model:\n",
    "            raise ValueError(\"无法找到本地模型文件，请确认bert-base-chinese-local目录路径\")\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_loader, val_loader, label_map = create_dataloaders(train_data, val_data, tokenizer, batch_size)\n",
    "    \n",
    "    # 计算标签数量和词汇表大小\n",
    "    num_labels = len(label_map)\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    print(f\"Vocabulary size: {vocab_size}\")\n",
    "    print(f\"Using {num_labels} labels for classification\")\n",
    "    \n",
    "    # 创建模型 - 使用我们的共享编码器MultitaskTransformer\n",
    "    model = MultitaskBertModel(\n",
    "        num_labels=num_labels\n",
    "    )\n",
    "    model.to(device)\n",
    "    \n",
    "    # 优化器和学习率调度器\n",
    "    # 优化器和学习率调度器\n",
    "    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    total_steps = len(train_loader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=total_steps // 5,  # 更多的预热步骤\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # 训练模型\n",
    "    results_history = train(\n",
    "        model, \n",
    "        train_loader, \n",
    "        val_loader, \n",
    "        optimizer, \n",
    "        scheduler, \n",
    "        device,\n",
    "        best_model_path,  # 添加这个参数\n",
    "        num_epochs=epochs, \n",
    "        eval_steps=eval_steps\n",
    "    )\n",
    "    \n",
    "    # 最终评估\n",
    "    if os.path.exists(best_model_path):\n",
    "        print(f\"加载最佳模型用于最终评估: {best_model_path}\")\n",
    "        model.load_state_dict(torch.load(best_model_path))\n",
    "        model.to(device)\n",
    "    else:\n",
    "        print(f\"警告：无法找到最佳模型文件 {best_model_path}，使用当前模型进行评估\")\n",
    "    \n",
    "    final_results = evaluate(model, val_loader, device)\n",
    "    \n",
    "    display(HTML(\"<h2>Final Evaluation Results</h2>\"))\n",
    "    display(HTML(f\"\"\"\n",
    "    <ul>\n",
    "        <li>Overall Accuracy: {final_results.get('overall_accuracy', 0):.4f}</li>\n",
    "        <li>Classify Accuracy: {final_results.get('classify_accuracy', 0):.4f}</li>\n",
    "        <li>NLI Accuracy: {final_results.get('nli_accuracy', 0):.4f}</li>\n",
    "        <li>Overall F1 Score: {final_results.get('overall_f1', 0):.4f}</li>\n",
    "    </ul>\n",
    "    \"\"\"))\n",
    "    \n",
    "    # 保存标签映射\n",
    "    label_map_inv = {v: k for k, v in label_map.items()}\n",
    "    with open(os.path.join(output_dir, \"label_map.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(label_map_inv, f, ensure_ascii=False, indent=2)\n",
    "    print(\"Label map saved for inference\")\n",
    "    \n",
    "    # 保存模型配置信息\n",
    "    config_info = {\n",
    "        \"vocab_size\": vocab_size,\n",
    "        \"num_labels\": num_labels,\n",
    "        \"task_types\": task_types,\n",
    "        \"training_params\": {\n",
    "            \"batch_size\": batch_size,\n",
    "            \"epochs\": epochs,\n",
    "            \"learning_rate\": lr\n",
    "        },\n",
    "        \"best_results\": final_results\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(output_dir, \"model_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(config_info, f, ensure_ascii=False, indent=2)\n",
    "    print(\"Model configuration saved\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:10:30.588644Z",
     "iopub.status.busy": "2025-05-18T08:10:30.588349Z",
     "iopub.status.idle": "2025-05-18T08:10:32.002911Z",
     "shell.execute_reply": "2025-05-18T08:10:32.002300Z",
     "shell.execute_reply.started": "2025-05-18T08:10:30.588622Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /root/Code/outputs/transformer_model/best_multitask_transformer.pt\n",
      "Checking if model file exists: False\n",
      "从本地加载分词器: ./bert-base-chinese-local\n",
      "模型文件不存在: /root/Code/outputs/transformer_model/best_multitask_transformer.pt，使用随机初始化的模型\n",
      "预测标签: 游戏\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/multi/lib/python3.10/site-packages/torch/nn/modules/transformer.py:505: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 添加项目根目录到Python路径\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# 导入我们自己的Seq2SeqTransformer模型\n",
    "from src.models.core_seq2seq import Seq2SeqTransformer\n",
    "\n",
    "# 修改后的基于共享编码器的多任务模型\n",
    "class MultitaskTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, num_labels=2, d_model=512, nhead=8, \n",
    "                 num_encoder_layers=6, num_decoder_layers=2, \n",
    "                 dim_feedforward=2048, dropout=0.1, max_seq_length=512, \n",
    "                 pad_idx=0):\n",
    "        super(MultitaskTransformer, self).__init__()\n",
    "        \n",
    "        # 实例化Seq2SeqTransformer作为共享编码器\n",
    "        self.seq2seq = Seq2SeqTransformer(\n",
    "            vocab_size=vocab_size,\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            max_seq_length=max_seq_length,\n",
    "            pad_idx=pad_idx\n",
    "        )\n",
    "        \n",
    "        # 任务特定的头部\n",
    "        self.classify_head = nn.Linear(d_model, num_labels)\n",
    "        self.nli_head = nn.Linear(d_model, num_labels)\n",
    "        \n",
    "        # 初始化权重\n",
    "        nn.init.xavier_uniform_(self.classify_head.weight)\n",
    "        nn.init.xavier_uniform_(self.nli_head.weight)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, src_padding_mask=None, task_type=None):\n",
    "        # 使用共享编码器提取特征 - 只使用encoder部分\n",
    "        memory = self.seq2seq.encode(src=input_ids)\n",
    "        \n",
    "        # 获取[CLS]位置的表示，用于分类（对应于第一个token）\n",
    "        pooled_output = memory[:, 0]\n",
    "        \n",
    "        if isinstance(task_type, list):\n",
    "            # 批处理多个样本时使用\n",
    "            results = []\n",
    "            for i, t in enumerate(task_type):\n",
    "                if t == 'classify':\n",
    "                    results.append(self.classify_head(pooled_output[i:i+1]))\n",
    "                elif t == 'nli':\n",
    "                    results.append(self.nli_head(pooled_output[i:i+1]))\n",
    "                else:\n",
    "                    results.append(self.classify_head(pooled_output[i:i+1]))\n",
    "            return torch.cat(results, dim=0)\n",
    "        else:\n",
    "            # 单个样本或同类型批次处理\n",
    "            if task_type == 'classify':\n",
    "                return self.classify_head(pooled_output)\n",
    "            elif task_type == 'nli':\n",
    "                return self.nli_head(pooled_output)\n",
    "            else:\n",
    "                return self.classify_head(pooled_output)\n",
    "\n",
    "# Function to load the saved model\n",
    "def load_model(model_path, vocab_size=21128, num_labels=139):\n",
    "    # 创建模型实例\n",
    "    model = MultitaskTransformer(\n",
    "        vocab_size=vocab_size,\n",
    "        num_labels=num_labels,\n",
    "        d_model=512,\n",
    "        nhead=8,\n",
    "        num_encoder_layers=6,\n",
    "        num_decoder_layers=2,\n",
    "        dim_feedforward=2048,\n",
    "        dropout=0.1,\n",
    "        max_seq_length=512\n",
    "    )\n",
    "    \n",
    "    # 尝试加载现有模型权重\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"加载现有模型权重: {model_path}\")\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    else:\n",
    "        print(f\"模型文件不存在: {model_path}，使用随机初始化的模型\")\n",
    "        \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Function to load the tokenizer\n",
    "def load_tokenizer(model_name=\"bert-base-chinese\"):\n",
    "    # 优先从本地加载\n",
    "    local_model_path = \"./bert-base-chinese-local\"\n",
    "    if os.path.exists(os.path.join(local_model_path, \"tokenizer_config.json\")):\n",
    "        print(f\"从本地加载分词器: {local_model_path}\")\n",
    "        return AutoTokenizer.from_pretrained(local_model_path, local_files_only=True)\n",
    "    else:\n",
    "        print(f\"本地分词器未找到，尝试在线加载: {model_name}\")\n",
    "        return AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Function to process the input and make a prediction\n",
    "def predict(model, tokenizer, input_data, device):\n",
    "    # 准备输入\n",
    "    input_text = input_data['input']\n",
    "    answer_choices = input_data['answer_choices']\n",
    "    task_type = input_data.get('type', 'classify')\n",
    "    \n",
    "    # 对输入进行tokenize\n",
    "    encoding = tokenizer(input_text, padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "    # 将张量移至正确的设备\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    src_padding_mask = (input_ids == tokenizer.pad_token_id).to(device)\n",
    "    \n",
    "    # 进行预测\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=input_ids, \n",
    "                      attention_mask=attention_mask,\n",
    "                      src_padding_mask=src_padding_mask,\n",
    "                      task_type=[task_type])\n",
    "    \n",
    "    # 获取预测的标签索引\n",
    "    predicted_label_idx = torch.argmax(output, dim=-1).item()\n",
    "\n",
    "    # 确保预测的索引在有效范围内\n",
    "    if predicted_label_idx >= len(answer_choices):\n",
    "        predicted_label_idx = len(answer_choices) - 1\n",
    "    \n",
    "    # 获取预测的标签\n",
    "    predicted_label = answer_choices[predicted_label_idx]\n",
    "    \n",
    "    return predicted_label\n",
    "\n",
    "# 加载模型和tokenizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 检测运行环境并设置相应的路径\n",
    "# 检测运行环境并设置相应的路径\n",
    "is_kaggle = os.path.exists('/kaggle') and '/kaggle/working' in os.getcwd()\n",
    "\n",
    "if is_kaggle:\n",
    "    model_path = '/kaggle/working/best_multitask_transformer.pt'\n",
    "else:\n",
    "    # 本地环境 - 使用相对或绝对路径\n",
    "    model_path = os.path.join(project_root, \"test_outputs\", \"multitask_model.pth\")\n",
    "    # 如果模型不存在，尝试其他可能的位置\n",
    "    if not os.path.exists(model_path):\n",
    "        model_path = os.path.join(project_root, \"outputs\", \"transformer_model\", \"best_multitask_transformer.pt\")\n",
    "    \n",
    "print(f\"Loading model from: {model_path}\")\n",
    "print(f\"Checking if model file exists: {os.path.exists(model_path)}\")\n",
    "\n",
    "local_model_path = \"./bert-base-chinese-local\"\n",
    "if os.path.exists(os.path.join(local_model_path, \"tokenizer_config.json\")):\n",
    "    print(f\"从本地加载分词器: {local_model_path}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(local_model_path, local_files_only=True)\n",
    "else:\n",
    "    print(\"本地分词器未找到，尝试从在线获取\")\n",
    "    model_name = \"bert-base-chinese\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 估计词汇表大小\n",
    "vocab_size = tokenizer.vocab_size\n",
    "num_labels = 139  # 从训练中获取的标签数量\n",
    "\n",
    "# 加载模型\n",
    "model = load_model(model_path, vocab_size, num_labels)\n",
    "\n",
    "# 定义输入数据\n",
    "input_data = {\n",
    "    \"input\": '这是关于哪方面的新闻： 故事,文化,娱乐,体育,财经,房产,汽车,教育,科技,军事,旅游,国际,股票,农业,游戏?投票事件过后，王者荣耀今后的日子该怎样走？',\n",
    "    \"target\": \"123\",\n",
    "    \"answer_choices\": [\"故事\", \"文化\", \"娱乐\", \"体育\", \"财经\", \"房产\", \"汽车\", \"教育\", \"科技\", \"军事\", \"旅游\", \"国际\", \"股票\", \"农业\", \"游戏\"],\n",
    "    \"type\": \"classify\"\n",
    "}\n",
    "\n",
    "# 预测\n",
    "predicted_label = predict(model, tokenizer, input_data, device)\n",
    "print(f\"预测标签: {predicted_label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7275609,
     "sourceId": 11600880,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "multi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
